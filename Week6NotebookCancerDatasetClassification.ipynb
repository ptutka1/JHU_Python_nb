{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patrick Tutka\n",
    "\n",
    "# HW\n",
    "Use the cancer data used below (or the first two columns of the iris data set) - for bonus, bring your own data set\n",
    "Normalize, test-train split the data\n",
    "Train models from SVM (linear and rbf kernels), LogRegression (2 values of C), KNN (3 neighbor values)\n",
    "Create two tables, one for train, one for test - that represent the Model, description, Precision, Recall, f1 score on each line\n",
    "Pick one of the Models and show the feature importance.\n",
    "\n",
    "Research webpage with attribute detail. \n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets, svm\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.preprocessing\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import svm, datasets\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix, auc, roc_curve)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_Linear</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_Regression C_1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_Regression C_3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN_10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN_15</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Precision  Recall  F1 Score\n",
       "0               SVM_Linear       0.99    0.96      0.98\n",
       "1                  SVM_rbf       1.00    0.87      0.93\n",
       "2  Logistic_Regression C_1       1.00    0.91      0.95\n",
       "3  Logistic_Regression C_3       0.99    0.95      0.97\n",
       "4                    KNN_5       0.98    0.96      0.97\n",
       "5                   KNN_10       0.99    0.95      0.97\n",
       "6                   KNN_15       0.98    0.94      0.96"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Table 1 summarizes the metrics for seven classification models that attempt to predict malignant breast cancer tumors. The metric parameters recorded were precision, recall, and F1 score. The model implemented a 70-30 train/test split and the above table represents metrics for the training data predicting malignant tumors. In addition, the data has been rescaled using the MinMaxScaler algorithm to transform the independent feature values to 0 to 1. Values classified as \"1\" were classified as malignent represented by the Y variable. Both logisitic regression C=3.0 and KNN with 5 nearest neighbors performed very well but I choose logisitic regression as the best training and test model. The below histogram represents important features that the model used to predict malignant tumors as \"1\". Bars moving to the right represent features that are strong predictors for cancer. Longer bars represent the strongest predictors for cancer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAEWCAYAAAC66pSsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBOxmZlZQf8f8EVAfa2SeZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f34dc97668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef1 = logReg3.coef_[0]\n",
    "plt.barh(list(range(coef1.shape[0])), coef1, align='center')\n",
    "# plt.yticks(range(len(X.columns)), X.columns)\n",
    "plt.title(\"Logistic Training Model Regression Feature Importance (Training Size = 70%)\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_Linear</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_Regression C_1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_Regression C_3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN_10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN_15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Precision  Recall  F1 Score\n",
       "0               SVM_Linear       1.00    0.91      0.95\n",
       "1                  SVM_rbf       1.00    0.79      0.88\n",
       "2  Logistic_Regression C_1       0.98    0.84      0.91\n",
       "3  Logistic_Regression C_3       1.00    0.91      0.95\n",
       "4                    KNN_5       1.00    0.95      0.97\n",
       "5                   KNN_10       1.00    0.88      0.93\n",
       "6                   KNN_15       1.00    0.88      0.93"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Table 2 summarizes the metrics for seven classification models that attempt to predict breast cancerbased on 30% test data. Logisitc regression C=3.0 and KNN_5 once again performed very well in predicting malignant tumors. The below histogram represents features that the model thought were important in predicting malignant tumors. Bars moving to the right represent features that are good predictors for cancer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEWCAYAAAAD/hLkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xm0HFW5/vHvA0EIJICYMAcCyGBE\nCBAQxasgg4AocEUFZRIVVPDCXU4IznAvXEVYTj8xDAKKIAookwpymUQZEuAyGBCEAJGQHEQIARQS\n3t8fex9S6dNnSE6fU7WT57NWr9NdVb3r7V3DW3vX7j6KCMzMzEq1TN0BmJmZDYYTmZmZFc2JzMzM\niuZEZmZmRXMiMzOzojmRmZlZ0WpJZJI+LOnqxXzvfZJ27HBIjSfpN5IOqTuOJpO0maR5A1z2E5J+\nP9QxWfMpuV3ShLpj6Y2kvSTdVnccw0nSypL+Imnl/pbtN5FJmi5pl86ElkTE+RGx2wDWfY6kE1ve\n+8aIuH5R1idpvKSQNDc/pks6dhHDrlVE7BER53ayzJwcu+vkZUkvVV6fPohyT5Z0Zj/LPCnpRUmr\ntEyflrfVmou7/sHKCbG6v8ztxElkIPXSabme3zac6+yNpFskHVh3HG3sB/wtIv6czznd2/ylfFx0\nv750cVcg6RhJV/SzzDaSrpf0j/y4VdI7ACLiiojYbnHX30mSPibpQUnPSpop6XRJK1Tmr5nPLS9I\n+quk91bmbZ/fO1vSxyrTV5Q0VdKY7mkRMQf4JXB0fzEtbV2Lq0bEKNKO+2VJu3Z6BZJGdLrMoZKT\n46hcJ+cD3+x+HRGfGIYQHgM+0P1C0nY0Z5+cX6mLUU04iZS0b1VJWkZSU7ZrO58AfgIQEYdWjolT\ngXMr+8C+QxWApOWAq4ALgLHAWsAXgBeGap2D8HvgzRGxCrAZsDZwXGX+j4EZwBjgU8BPJa2f550K\nHAy8FfiWpNF5+peBH0XEUy3rOh/4eL/7T0T0+QCmA7v0Mu/jwEPA08BlwNqVebsBDwDPAv8PuAH4\nWJ53KPCH/FzAacDsvOzdwObA4cDLwEvAXODy1niAZXMF/hV4DpgKjGsT53gggBGVabcBn6u8Xhu4\nGOgCHgH+ozJvJHAu8A9gGvB5YEZLHX0hx/4vYEQ/5W0HTAHmALOAU/P0FYCfAn8HngFuB9bI866v\n1N8ywJeAR3O9nQes0vJZDyEliqeA4wewnc8BTmwzfd/8uZ4BbgImVOZ9GZiZP8c04N+AffI2ezlv\nt9t6Wd+T+TPcVJn2feD4HP+aedpqwM8q9fh5QHneCOA7ub4eAj4NzKuUt1qumyeBx4GvAsvkeZ8A\nft9LbJtVy2kz/wjSvv00cCWwTmXeD0kH8Zy8j22fp7etlxzb2yrvPxk4sxoH6Th7HLg6T/834Na8\nTe4Adugj1lfLz5/5f3M9Pws8CEwiHWt/I+2L+1feeyHwPeA60vF1bctnfUde/7PALcC2lXm3AN/I\ncf4TOAuYn5/PBb7dV31V6uJ80sn9OdJ+OLHluP41aR9/qrvM/rZRS/2smLfJmDbzXt0WLdPfSTo2\nnyEdx2+uzDuSdNw9R9on9wbeQjovzMuffXqbMl+f62fZXuLcB7g3Pz88l9P9eAn4VZ63EvCDXKcz\nSefW5fo7/hf3AawCXAr8LL9eI3/ONSvLXA4cm58/XJl+P7AJMIF0blEv65gNbNlnHAMIdDptElne\nmE8BWwPL5x3+xjxvTN4x/510sjk67yztEtm7SAloVVJSewOwVp53Di0nVxZOZJ8D7gE2ze/dEnhd\nm1jHU0lkwPakK5198+tlcgxfAV4DbAg8DLyrskPfALwWWJd0QLUmsruAcaSk1195fwIOys9HseBk\nd0Te6CuSkvQ2wMp53vWV+juMdJBsmN9/CfCTls96Ro5lS9JB9IZ+tnO7ut6edDBsk+M5HPhL3qZb\n5s+0Rq77DYEN+joBtJT9JOmE/Eh+73J5XRuycCK7CPhF/pyvz8t/OM87Jm//tUlXsX9g4UT2G9J+\nuSLpCvdO4JA8b7ESGbA/KWlvkmM+EbiuMv/gvJ8sR0rKj5NPJO3qhf4TWQBn5s8wMm/fvwO7kPaz\nPUlJ/rV91HM1kb0MfChvw2+RLoZOI+2n7yVdrK2Ql7+QdLJ+C+ki6/TuOgNWJx3jH8hlHZrj6L6g\nuiXvH5vmuhiRpx3YEl9/9fUCsCtp/zsNuD7PWy5vh5MrdfPWgWyjlvVvA/y9l3ntttfGuf53zPW/\nb67j0cCapHPi+LzsusCmlX31ij6Oh+VJFxO/AN5DS2Klkshapo8lHRP7V47jnwEr53q9DvhCL+t8\nd96+vT3e1Ee8787bP/Ky3XW/EzCzZdkTWXB+uoZ03G9MunBakXSBtHUf67oROLjP80lfM3Mh02mf\nyM4idUV1vx5FOkjG553zT5V5yjtou0T2TtLJcXvy1XLlfefQdyJ7ANh7AJ9hfKXCX8zPT2HBlf2b\ngcda3vNF4Mf5+atJKL/+GD0T2WGV1/2VdyPw9TY762HAH4Et2nyG6yv1dy3wqcq8TXPdj6h81nUr\n82+jcqXdSx21q+sf09KaI5343gy8kZR4dqLS0u3tBNBmfU8Cb8s7+VdJB+rleT8K0klhedJV6oaV\n9x0N/DY//yNwaGXee8kJCFgfeJ7K1SjwEeA3+Xl/iax7f+l+HJXnXUdOpPn1crnu12hTjkgn4k17\nqxcGlsiqPR1fBc5oKeMG4IN91XPlM99TmbdtLn+VyrTngc3y8wuBcyrzVsvLjyW1Em9sWdedLDih\n3gIc1zK/RyIbQH1dUZm/NfBMfr4T6cS/TJtyFmUb7UybFlIf2+sk4Hst024ltbxWJ10IvBtYvmWZ\nPhNZXmZDYDLpGJsPXE3uYaJNIsuf6wbgpPx6JKk1NKayzB7AnX2tdzAP0vnmG8B6+fV7gPtblvkc\nC1qMm5K6JqeQjteDSRebG5O6Vq8H9mx5/5VUerTaPQbTb712rnAAImIu6UplnTzv8cq8IDV1e4iI\n7q6OHwCzJE0eyCiVbBypW3GgxpBOlJ8lXVEtl6evD6wt6ZnuB6nLco08f6HP0/K83bT+yvso6Wrx\n/jxaaq88/SfA74ALJT0h6Zu577zVQnWfn4+olA/pBNbthfy5F9X6wHEtn2MsqZvmPuBY4L+A2ZLO\nl7RGX4X14jzgQNIOfV7LvDVJV72PVaY9StrHoOd2qdbJ+qRWRFcl9u+wcB31ZX5ErFp5fL9S7umV\nMrtIJ491ASR9UdIDkp4lt25I+93ieiUinmj5XAe2bJNJpLoYiFmV5y8C/4qIZ1umVfeV6nH8NKkr\na2167oOw8LZZ6L29GUB99bYfjwMeiYhX2hTb5zZq8Q9Sa2qg1gc+1lL/m5MuNmaTLpY+SzqXXSpp\ng4EWHBEPR8ThEbE+6cS+Aimx9ea7pC7M4/PrcaSW60OV2C4kJdghERHTSReU5+RJc0mtwaqVc5xE\nxAMRsUtETCJ1J36WdIvhB6Q88AHgjOrgEdL2eaavOAaTyJ4gbVQAJK0EvI50lTSTyk4jSbTfiQCI\niO9GxDakq/xNSBkc0tVfXx4HNlqUoCNifkR8m9RX/6lKOY+0nLhGR8Seef5Cn4e0w/QouiWuXsuL\niAcj4gDSDvY/wC8lrRQRL0fE1yNiAulm6F6kE3yrheoeWI90oM5qs+xgPA58peVzrBgRl+TPcW5E\nvJV0JbkCqXUF/W+3V0XEX1jQVXNZy+wngVdIn6/beqR9DNJ2Gdcyrxr7XFKXW3fsK0fE1gONrReP\nk1qB1ToZGRFT8+ChT5O6m1YltWBeJLU0oH29PE/qXunWOlqz9T2Pk1oJ1fWvFBGnDfJz9ebV+pW0\nGimRzKTnPggLbxvoGftCrwdQX315HBjfyyCAXrdRm2WnAaOro+UGsN7vt6n/HwJExK8iYidSQu8i\nJRtYhGMil/MwKYlt3m6+pCNIx8yHKsl8BqklN64S2yoRsU4vZezVMjK39fGmAYY7ggXn4T8Dq7dc\n1G4J3NfmfSeRevWeBd4ETMkXA3NY+FjeDPi/vgIYaCJbTtIKlccIUj/sRyRNlLQ88N/ArTlDXwm8\nSdI+edkj6XmAAiBpW0lvzi2P50kJZn6ePYt0kuzNmcAJkjZWsoWk1w3wM50MfD5n/tuAOZK+IGmk\npGUlbS5p27zsRcAXJb1W0jrAUf2U3Wd5kg6UNDbvgN1XGvMl7STpTZKWJW3Mlyt1UXUB8J+SNpA0\nilT3P4+IAX2HahFMBj4taVKu31GS3puHyk6Q9I687V/Mj+p22yBfwAzEQcDOEfGv6sT8+lLgvyWt\nJGkjUtfiT/MiF5HqYa18Ivp85b2PkLqyvilpdB45t7EGPxT9dOBLkjYFyPvE+/K80aRt1kW65/QN\nUoLv1q5e7gIOkDRC0vakLqq+nAu8X9LOeb8amZ8P1dcV9s7H5/IsuNc0m3TRsZWk/XLsB5NOPr/t\no6zW47m/+urLH0hX+Sfk/XGkpLfmeX1to4VExIuk7qy3D3C9Pya1iN+R96mRknaTNFbS+pJ2lzSS\ndF/6eRY+JtZTLyNPJY2TdJzSV4UkaS3SRewtbZZ9G3AC6bbKnMpneYE0OOY7klbL5awvaedePvsV\nsfDI3NbHPb3EeqiktfPz15O6u6/NZc4idR2ekOtmV1LCvaCljO2ATSKi+1h+BHinpPGkXDEzLzch\n12XbWLoNNJFdxYKT1YvA1yLiWtKotYvzSjci3WQl0hDK9wPfJF1tTyD1if6rR8mp2XkGqYn/aF7+\nlDzvLGCCUjP5V23eeyrpZHY16cR/FqmfeCCuzOv8eETMJ/XtTiRV6FOkJNn9HadvkK52HiFtpF/2\n8lmA1Orrp7zdgfskzSV1d+0fEf8kbcBfsmAU4A0sOGlXnU3qhrwxl/9P0pVtR0XEzcB/AD8iJdy/\nkAYKBKmev50/20zSlfpX8lsvJLUynpb0xwGs58GIuLOX2Ufkv4+SRtydSTpYIXVF3ES62ruVtC9U\nHUC60r+fNHrt5wy8a7G3WC/I671E0hxSIur+GsflpG3yV9J91adIJ+lu7erlONLV6DOk+6gX9rP+\nh4H3ke6xPkWql6MZuq8t/JR00fcUaSDWITmOWaR7HMeTjtmjgL0ioq8uoNOAg5W+I/VN+q+vXkXE\ny6SBLluSjs3HSIPL+ttG7fyIdDE1kPXeTzrPnUT63NNZ0LMzgnQMzMqf443Af+Z5V+RpXZLa3Q55\nIS9/E6knYSqp1fvJNsvuRxrIcYcWtJ66E8WnSKNI78x/ryDdx+qkrYGpkp4nHZO3sPB3vT5Cuqj5\nO+mi4qCIeLUbOl+of4+FGwSfIV0o3QZ8PiKey9M/TLon3K4L+VXdgx2GlFLzfwbpBux1Q77CISbp\nk6Tk8466YzEbKpIuJA0wOLHfhQuWW8i3kroj/1x3PJYojZWYAkyqtjzbGbIvKUp6l6RVc5fEcaR+\n7x7N5BLkrqsdclfCpqSrh8X+lr+ZNUck2zmJNUtEzImITfpLYpCawkPlLaT7aK8h3QDcJ/dHl+g1\npO6HDUhdQBeSvuRtZmY1G5auRTMzs6HS5N8/MzMz61eRP0LazpgxY2L8+PF1h2FmVpSpU6c+FRFj\n645jMJaYRDZ+/HimTJlSdxhmZkWR1PoLLcVx16KZmRXNiczMzIrmRGZmZkVzIjMzs6I5kZmZWdGc\nyMzMrGhOZGZmVjQnMjMzK9oS84VoWzqNP/bKukNY4k0/+d11h2DWJ7fIzMysaE5kZmZWNCcyMzMr\nmhOZmZkVzYnMzMyK5lGLVjSPqDMzJzIrmoffm/mCzl2LZmZWNCcyMzMrmhOZmZkVzYnMzMyK5kRm\nZmZF86hFK9rSPlrLzJzIrHAefl8vX0hYE7hr0czMiuZEZmZmRXMiMzOzojmRmZlZ0TzYw4rmwQZm\nVmuLTNI4SddJmibpPklH5+lfk/Q3SXflx551xmlmZs1Vd4tsHvCZiLhD0mhgqqRr8rzTIuKUGmOz\nAizNw+/dGjVLak1kETETmJmfPydpGrBOnTGZmVlZGjPYQ9J4YCvg1jzpKEl3Szpb0mtrC8zMzBqt\nEYlM0ijgYuCYiJgD/BDYCJhIarF9u5f3HS5piqQpXV1dwxavmZk1R+2JTNJypCR2fkRcAhARsyJi\nfkS8ApwBbNfuvRExOSImRcSksWPHDl/QZmbWGLXeI5Mk4CxgWkScWpm+Vr5/BrAvcG8d8VnzecCD\nmdU9anEH4CDgHkl35WnHAQdImggEMB04op7wzMys6eoetfgHQG1mXTXcsViZlubh94vDLVhbEtV+\nj8zMzGwwnMjMzKxoTmRmZlY0JzIzMyta3aMWzQbFgxfMzC0yMzMrmltkVjQPvy+TW9LWSW6RmZlZ\n0ZzIzMysaE5kZmZWNCcyMzMrmgd7WNE8aMDMnMisaB61WDZfiFgnuGvRzMyK5kRmZmZFcyIzM7Oi\nOZGZmVnRnMjMzKxoHrVoRfOoNzNzIrOiefh9eXzxYZ3mrkUzMyuaE5mZmRXNiczMzIrmRGZmZkVz\nIjMzs6J51KIVzSPgzKzWRCZpHHAesCbwCjA5Ir4jaTXg58B4YDrwgYj4R11xWnN5+P2SyRcotijq\n7lqcB3wmIt4AbA8cKWkCcCxwbURsDFybX5uZmfVQayKLiJkRcUd+/hwwDVgH2Bs4Ny92LrBPPRGa\nmVnT1d0ie5Wk8cBWwK3AGhExE1KyA1bv5T2HS5oiaUpXV9dwhWpmZg3SiEQmaRRwMXBMRMwZ6Psi\nYnJETIqISWPHjh26AM3MrLFqT2SSliMlsfMj4pI8eZaktfL8tYDZdcVnZmbNVveoRQFnAdMi4tTK\nrMuAQ4CT899f1xCeFcCj28ys7u+R7QAcBNwj6a487ThSArtI0keBx4D31xSfLYbhHBLvRGZmtSay\niPgDoF5m7zycsZiZWZlqv0dmZmY2GE5kZmZWNCcyMzMrmhOZmZkVre5Ri7YE8khCMxtOTmQ2rDo9\nNN9J08zctWhmZkVzIjMzs6I5kZmZWdGcyMzMrGge7GHDyoMzzKzT3CIzM7OiuUVmRWs3nN+tPrOl\ni1tkZmZWNCcyMzMrmhOZmZkVzYnMzMyK5sEeVjQP7DAzt8jMzKxoHWuRSdoE+CGwRkRsLmkL4L0R\ncWKn1mFLh0X5hXy3yMysky2yM4AvAi8DRMTdwP4dLN/MzKyHTiayFSPitpZp8zpYvpmZWQ+dTGRP\nSdoICABJ+wEzO1i+mZlZD50ctXgkMBnYTNLfgEeAD3ewfDMzsx46ksgkLQNMiohdJK0ELBMRz3Wi\nbFv6eACHmS2KjiSyiHhF0lHARRHx/EDfJ+lsYC9gdkRsnqd9Dfg40JUXOy4irupEnDY0FmWUYac5\n6ZlZJ++RXSPps5LGSVqt+9HPe84Bdm8z/bSImJgfTmJmZtarTt4jOyz/PbIyLYANe3tDRNwoaXwH\nYzAzs6VMxxJZRGzQqbKAoyQdDEwBPhMR/2i3kKTDgcMB1ltvvQ6u3szMStHJX/Y4uN30iDhvEYv6\nIXACqTV3AvBtFrT2WsueTBopyaRJk2IR12NmZkuATnYtblt5vgKwM3AHsEiJLCJmdT+XdAZwRUei\nMzOzJVInuxY/XX0taRXgJ4tajqS1IqL7i9T7Avd2IDwbQh45aGZ1Gsp/4/ICsHFfC0i6ANgRGCNp\nBvBVYEdJE0ldi9OBI4YwRitcu6H/TqxmS5dO3iO7nPzzVKRh/ROAX/T1nog4oM3kszoVk5mZLfk6\n2SI7pfJ8HvBoRMzoYPlmZmY9dPIL0XtGxA35cXNEzJD0Px0s38zMrIdOJrJd20zbo4Plm5mZ9TDo\nrkVJnwQ+BWwo6e7KrNHAzYMt38zMrC+duEf2M+A3wEnAsZXpz0XE0x0o36xXHqFoZoNOZBHxLPAs\ncACApNVJX4geJWlURDw22HWY9abOX97vBCdis8Hr2D0ySe+R9CDpH2reQPoO2G86Vb6ZmVk7nRzs\ncSKwPfCX/APCO+N7ZGZmNsQ6mchejoi/A8tIWiYirgMmdrB8MzOzHjr5hehnJI0CbgLOlzSb9MVo\nMzOzIdPJFtnepN9XPAb4LfBX4D0dLN/MzKyHTv76/fOS1gc2johzJa0ILNup8s3a8ag/M+vkjwZ/\nnPTfmlcDNgLWAU4nDfowGxJNGH7vZGpWr052LR4J7ADMAYiIB4HVO1i+mZlZD51MZP+KiJe6X0ga\nwYJ/62JmZjYkOpnIbpB0HDBS0q6k/0V2eQfLNzMz66GTiexYoAu4h/Rfna8CvtTB8s3MzHroxK/f\nrxcRj0XEK8AZ+WFmZjYsOjFq8VfA1gCSLo6I93WgTLMB8YhBM+tEIlPl+YYdKM/60YQh503hRGZm\nnbhHFr08NzMzG3KdaJFtKWkOqWU2Mj8nv46IWLkD6zAzM2urE/9Y0z9DZWZmtenk8HszM7Nh18l/\n42LDxAMczMwWqL1FJulsSbMl3VuZtpqkayQ9mP++ts4YzcysuZrQIjsH+D5wXmXascC1EXGypGPz\n6y/UEJs13JL6VQS3us0GrvYWWUTcCDzdMnlv4Nz8/Fxgn2ENyszMilF7IuvFGhExEyD/9b+DMTOz\ntpqayAZE0uGSpkia0tXVVXc4ZmZWg6YmslmS1gLIf2e3WygiJkfEpIiYNHbs2GEN0MzMmqEJgz3a\nuQw4BDg5//11veFYU3lQhJnV3iKTdAHwJ2BTSTMkfZSUwHaV9CCwa35tZmbWQ+0tsog4oJdZOw9X\nDEvqEO6lgVtkZlZ7i8zMzGwwnMjMzKxoTmRmZlY0JzIzMyta7YM9msADBszMyuUWmZmZFc0tMhsW\nQ/UVB7emzcwtMjMzK5oTmZmZFc2JzMzMiuZEZmZmRfNgDxsWHpRhZkPFicyK5h98tqHmi7Dmc9ei\nmZkVzYnMzMyK5kRmZmZFcyIzM7OiOZGZmVnRPGrRiuYRZWbmRGZF8/D7svjCw4aCuxbNzKxoTmRm\nZlY0JzIzMyuaE5mZmRXNiczMzIrmUYtWNI+CM7PGJjJJ04HngPnAvIiYVG9E1kQDGX7vZGe2ZGts\nIst2ioin6g7CzMyay/fIzMysaE1OZAFcLWmqpMPbLSDpcElTJE3p6uoa5vDMzKwJmpzIdoiIrYE9\ngCMlvb11gYiYHBGTImLS2LFjhz9CMzOrXWMTWUQ8kf/OBi4Ftqs3IjMza6JGDvaQtBKwTEQ8l5/v\nBnyj5rCsgTwi0cwamciANYBLJUGK8WcR8dt6QzJo3q/NO5GZWSMTWUQ8DGxZdxxmZtZ8jb1HZmZm\nNhBOZGZmVjQnMjMzK1oj75FZc3lwhZk1jVtkZmZWNLfIrGhN+zpAydzatlK5RWZmZkVzIjMzs6I5\nkZmZWdGcyMzMrGge7GFF8wAFM3OLzMzMiuYWmRVtaRp+79anWXtukZmZWdGcyMzMrGhOZGZmVjQn\nMjMzK5oHe1jRPADCzNwiMzOzorlFZkUrbfi9W5BmnecWmZmZFc2JzMzMiuZEZmZmRXMiMzOzonmw\nhxXNgyfMrLGJTNLuwHeAZYEzI+LkmkOyBipt1OKicqI2618juxYlLQv8ANgDmAAcIGlCvVGZmVkT\nNTKRAdsBD0XEwxHxEnAhsHfNMZmZWQM1NZGtAzxeeT0jT1uIpMMlTZE0paura9iCMzOz5mhqIlOb\nadFjQsTkiJgUEZPGjh07DGGZmVnTNDWRzQDGVV6vCzxRUyxmZtZgTR21eDuwsaQNgL8B+wMfqjck\nayKP6jOzRiayiJgn6Sjgd6Th92dHxH01h2VmZg3UyEQGEBFXAVfVHYeZmTVbU++RmZmZDYgTmZmZ\nFc2JzMzMiuZEZmZmRXMiMzOzojmRmZlZ0ZzIzMysaIro8ROGRZLUBTxadxxDbAzwVN1BNIzrpCfX\nSU+uk56662T9iCj6x2qXmES2NJA0JSIm1R1Hk7hOenKd9OQ66WlJqhN3LZqZWdGcyMzMrGhOZGWZ\nXHcADeQ66cl10pPrpKclpk58j8zMzIrmFpmZmRXNiczMzIrmRFYYSe+XdJ+kVyQtEUNnF5ek3SU9\nIOkhScfWHU/dJJ0tabake+uOpSkkjZN0naRp+bg5uu6Y6iZpBUm3Sfq/XCdfrzumwXIiK8+9wL8D\nN9YdSJ0kLQv8ANgDmAAcIGlCvVHV7hxg97qDaJh5wGci4g3A9sCR3k/4F/DOiNgSmAjsLmn7mmMa\nFCeywkTEtIh4oO44GmA74KGIeDgiXgIuBPauOaZaRcSNwNN1x9EkETEzIu7Iz58DpgHr1BtVvSKZ\nm18ulx9Fj/pzIrNSrQM8Xnk9g6X8BGV9kzQe2Aq4td5I6idpWUl3AbOBayKi6DoZUXcA1pOk3wNr\ntpl1fET8erjjaSi1mVb0VaUNHUmjgIuBYyJiTt3x1C0i5gMTJa0KXCpp84go9t6qE1kDRcQudcdQ\ngBnAuMrrdYEnaorFGkzScqQkdn5EXFJ3PE0SEc9Iup50b7XYROauRSvV7cDGkjaQ9Bpgf+CymmOy\nhpEk4CxgWkScWnc8TSBpbG6JIWkksAtwf71RDY4TWWEk7StpBvAW4EpJv6s7pjpExDzgKOB3pBv4\nF0XEffVGVS9JFwB/AjaVNEPSR+uOqQF2AA4C3inprvzYs+6garYWcJ2ku0kXhNdExBU1xzQo/okq\nMzMrmltkZmZWNCcyMzMrmhOZmZkVzYnMzMyK5kRmZmZF8xeibakmaT5wT2XSPhExvaZwzGwxePi9\nLdUkzY2IUX3MH5G/s2ZmDeWuRbMWkg6V9AtJlwNX52mfk3S7pLur/79J0vH5f6L9XtIFkj6bp1/f\n/f/iJI2RND0/X1bStyplHZGn75jf80tJ90s6P/8qBZK2lfTH/P+jbpM0WtJNkiZW4rhZ0hbDVUdm\nTeKuRVvajcy/Ag7wSETsm5+/BdgiIp6WtBuwMelfxwi4TNLbgedJP421FelYugOY2s/6Pgo8GxHb\nSloeuFnS1XneVsAbSb8ZeTOwg6TbgJ8DH4yI2yWtDLwInAkcChwjaRNg+Yi4e1A1YVYoJzJb2r0Y\nERPbTL8mIrr/t9du+XFnfj2KlNhGA5dGxAsAkgbyW4+7AVtI2i+/XiWX9RJwW0TMyGXdBYwHngVm\nRsTtAN2/3C7pF8CXJX0OOIxAaj73AAABOklEQVT0TzXNlkpOZGbtPV95LuCkiPhRdQFJx9D7v46Z\nx4Ku+xVayvp0RCz0G5mSdiT9595u80nHp9qtIyJekHQN6Z+JfgCY1M/nMVti+R6ZWf9+BxyW/6cV\nktaRtDpwI7CvpJGSRgPvqbxnOrBNfr5fS1mfzP9aBEmbSFqpj3XfD6wtadu8/GhJ3RegZwLfBW6v\ntB7NljpukZn1IyKulvQG4E95/MVc4MCIuEPSz4G7gEeBmypvOwW4SNJBwP9Wpp9J6jK8Iw/m6AL2\n6WPdL0n6IPC9/C83XiT92425ETFV0hzgxx36qGZF8vB7sw6R9DVSgjllmNa3NnA9sFlEvDIc6zRr\nInctmhVI0sHArcDxTmK2tHOLzMzMiuYWmZmZFc2JzMzMiuZEZmZmRXMiMzOzojmRmZlZ0f4/D8dX\nWoWc9p8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f34dc701d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef2 = logReg4.coef_[0]\n",
    "plt.barh(list(range(coef2.shape[0])), coef2, align='center')\n",
    "plt.title(\"Logistic Regression Test Model Feature Importance (Test Size = 30%)\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcHHW57/HPNyEhgQQCSWRJghMQ\nkBAhhkFBPIqCbG7oAQFlC0tEwQv3iBJBJYL3iucqCsKBEySCyiKKuMKBKCLKYggY1oCgjDISyMKS\nsEQIee4fv99Ap+mZ6Uymu7p7vu/Xa17TXVVd9dTS9fSvfk9XKyIwM7OBbVDRAZiZWfGcDMzMzMnA\nzMycDMzMDCcDMzPDycDMzBhAyUDSJyTd0MfX3i9p934OqeFJuk7SEUXHsTYk7S6ps4fxF0r6Uo2W\nHZLeVIt5r+0ye9suNvA0ZDKQ1CFpz/6cZ0RcFhF7VbHsSyR9tey120fETWuyPElt+Y35XP7rkDRj\nDcMuVETsGxGX1mLekt4m6VpJz0h6StJcSdNqsayeRMRxEXFmvZcr6aZ8fOxYNvxnefju9Y6pLI6Q\n9HzJ8ftMP8zzSEl/7I/41mCZN0k6pp7L7E6lc0sjachk0GJGRcQI4ADgS5Le198LkLROf8+zliTt\nCtwI/B54EzAa+BSwb5FxFeAvwOFdTySNBnYBFhcW0ep2jIgR+W9U0cE023FeStLgomPoVUQ03B/Q\nAezZzbhjgUeAp4BfAJuXjNsLeAh4Fvgv0snmmDzuSOCP+bGAbwGL8rT3AJOB6cDLwEvAc8Avy+MB\nBgOnAn8FlgN3AhMqxNkGBLBOybC5wOdKnm8OXE168z8K/K+SccOBS4GngQXA54HOsm10So79X8A6\nvczvbcA8YBnwJHB2Hj4M+CGwFHgGuAPYJI+7qWT7DQK+CPw9b7fvAxuWresRwD+AJcBpPezfPwLn\n93IM9LSfA/g08HDeB2cCWwG35fW7Chiap90d6Mz7bEnebp8omdclwFfLpv1sXseFwLSSadcFvpHX\n8UngQmB4yfjP5dc8DhyV43xTN+t3E/DlvLzBedgJwAV52O4ly/x2nufj+fG61Syzp3i71rWH7d9T\n7B8A5ufj5VZgh5JxM3jtvfEA8JE8fDtgBfAK6b31TPkxVv4+LYnj+LyvH83D3gzMycfGQ8DHeliP\nV+dfsn8/X7J/9wf2IyXmp4BTS147E/gJ8KO8PneREiQl63RT3g73Ax8qO64uAK4Fnqf7c0vF7VW6\nLfI+fJr0nt63ZPzGwPfyvn8a+Fk1+6jbbbW2J+5a/NFNMgDeS3pDT80H+neAm/O4MaQTwUdJJ8YT\n88avlAz2Jp3ER5ESw3bAZuUnh0rxkN589wLb5tfuCIyuEGsbJcmA9InvBV57cwzKMXwZGApsCfwN\n2DuPP4uUzDYCxpNO+uXJYD4wgZQ4epvfbcBh+fEIYJf8+JPAL4H1SIluJ2CDCm+ko0gn5y3z638K\n/KBsXS/KsexISlDbVdgu65FOCO/pYf93u59LThC/ADYAts/L+m2ObUPSm+qIkhPASuDsPK93k96c\n25bv75JpzwCGkE4SLwAb5fHfzsvdGBiZt9vX8rh9SCfcycD6wOX0ngyOAW4gv8FJHxZ2ZfVkcAZw\nO/AGYCzpjX1mNcvsJd7d6UMyyPtkEfD2fLwcQToW183jDyR9KBkEHJS3ddd760hKTvTlx1ilaXIc\nc/I6DM/r+RgwjfQ+n0o6VrbvaTuX7d8v5/17LOmD0+V5+2xPSlhb5ulnks4hB+TpTyadkIfkv0dI\nHzKGko7Z5ax+XD0L7Ja3xTAqn1t6214v5zgHk1rPjwPK439NSlQb5XjeXc0+6nafF33i72YHdlA5\nGVwM/GfJ8xF5Y7WRmtu3lYxTPmgqJYP3kj4J7AIMKltGpR32ajykTyIfrmId2vKB/AzwYn78jZId\n+XbgH2Wv+QLwvfz41RN5fn4Mr08GR5U8721+NwNfAcaUTXMU3XxyYPU30m+BT5eM2zZv+3VK1nV8\nyfi5wMEV5jkuT/vmHrZdt/u55ASxW8n4O4FTSp5/E/h22Qlg/ZLxVwFfKt/fedoXWb01tygfJyK9\nUbcqGbcrr31anQ2cVTJuG6pLBocCV+Tt+Zc8rjQZ/BXYr+R1ewMdvS2zinh3p/dksIx0/D4DnJuH\nX0BORiXTPkQ+EVWYz3zy+4W+J4P3ljw/CPhD2Tz+Gzi9p+1ctn+7WmIj8/zfXnYs7Z8fzwRuLxk3\niNSa+Lf89wQl54+8H2eWHFffL4vlEsrOLVVsr0dKxq2X490U2AxYRf6gUjaPNdpHXX/Ndg1uc1JT\nDYCIeE7SUtIJZnPSyb9rXHRXLRERN0o6Dzgf2ELSNcDJEbGsihgmkN6g1RpD2oEnAYeQMvhLwBuB\nzcs65gYDf8iPV1ufsseVhvU2v6NJnzIflPQo8JWI+BXwg7xOV0oaRbpkdFpEvFy2rM1Jl4i6/J2U\nCDYpGfZEyeMXSCfxck+TDuLNgAcrjO9aVnf7uSMPfrJk+hcrPN+0dJkR8XxZ7Jt3s+ylEbGywnqM\nJb0Z75TUNU6kbdwV851ly6jGT0nJaylpX5SrtN03LxnX3TJ7i7caUyPikbJhbwSOkPSZkmFDu2KS\ndDjwH6QPCJC23Zg1WGYl5cf528uO83WovO0qWRoRr+THL+b/5cdO6XFbek5Zlc8pXdv/sYhYVTLt\n30nHaKW4K6pie736noqIF/K+HEFqKT0VEU9XmG2P+6g7zdaB/DhpRQGQtD6p8/GfpIw9vmScSp+X\ni4hzI2InUtNwG9LlH0gn7p48Rro+XbWIeCUivklqgn66ZD6PRsSokr+REbFfHr/a+pBO2K+bdVlc\n3c4vIh6OiENIlxu+DvxE0voR8XJEfCUiJgHvIF1rPLx8QZRte2AL0ifuJytM262IeIF0yerfe5is\np/3cFxvleXTZIi9jTSwhnSi2L9m+G0YqDoC0v0r30RbVzDRvj+tIlwAqndAqbfeu2HtaZm/x9tVj\nwP8pO87Wi4grJL2RdKnwBNKl01HAfaQkBJXfW8+TklaXTStMU36c/75s+SMi4lNruV7deXX7ShpE\nek929d9MyMO6bMHqx2j5+q72vIrt1ZPHgI3zB7hK4yruo55m2MjJYIikYSV/65Cu7U2TNEXSusD/\nBf4UER2k62dvkbR/nvZ4Kh9YSNpZ0tslDSEdjF0dW5BOblv2ENd3gTMlba1kh1wFUo2zgM9LGka6\njLJM0imShksaLGmypJ3ztFcBX5C0kaRxpAOmJz3OT9KhksbmTzJdn6pekfQeSW/J1Q7LSJdjXqkw\n/yuA/y1poqQRpG3/o7JP0dX6PHCkpM91bTtJO0q6Mo/vaT/31VckDZX0b6SE9+M1eXHebhcB35L0\nhhzzOEl750muyus0SdJ6wOlrMPtTSU34jgrjrgC+KGmspDGk690/7G2ZVcTbVxcBx+X3jyStL+n9\nkkaSrucHuRoqlwpPLnntk8B4SUNLhs0HPippPaXvRxzdy/J/BWwj6TBJQ/LfzpK2W8v16s5Okj6a\nzyknkfqnbgf+RDp3fD7HsDvwQeDKbuf0+nNLb9urWxGxkPQh4r/yOWKIpHfl0T3to241cjK4lvTJ\nputvZkT8FvgSqWJmIekT+sEAEbGE1Bnzn6Qm9yRS9cy/Ksx7A9IGe5rUtFtKup4P6Xr1JKX6959V\neO3ZpDfhDaST58Wkjq1q/Dov89jcVP0gMIXUKbWElGg2zNOeQbp2/CjwG1JVQ6V1AVLro5f57QPc\nL+k54BzS9fwVpIT5k7wuC0id1j/k9WaTPrnenOe/AvhMhel6FRG3kvpt3gv8TdJTwCzSPqen/dxH\nT5C2++PAZcBxEdHdJaqenELqNLxd0jLSftk2x3wdqcP2xjzNjdXONCIej4ju6u+/SjqO7yEVLtyV\nh1WzzG7j7auImEfq0DyPtE0fIV3bJiIeIF3yuo104nsLcEvJy28kVd08IWlJHvYt0mXTJ0nVc5f1\nsvzlpKrBg0n78wlSS3fdtVmvHvyc1E/xNHAY8NHcmn4J+BCpHHoJqXrx8F6Oq9XOLVVsr94cRvrw\n9iCpb+sk6Hkf9aSrM7Pl5OZbJ6mM8HdFx7O2JH2KdAJ/d9GxmA0EkmaSCgAOLTqWemjklsEak7S3\npFH50sKppGtvtxccVp9I2kzSbpIGSdqWVPt+TdFxmVlrarZqot7sSrrePJRUa75/RLzY80sa1lBS\nydxE0jX+K0lNUTOzfteyl4nMzKx6LXWZyMzM+qYpLhONGTMm2traig7DzKyp3HnnnUsiYmw10zZF\nMmhra2PevHlFh2Fm1lQkVftNeF8mMjMzJwMzM8PJwMzMaJI+g0pefvllOjs7WbFiRdGh1MWwYcMY\nP348Q4YMKToUM2tBTZsMOjs7GTlyJG1tbUjV3OSveUUES5cupbOzk4kTJxYdjpm1oKa9TLRixQpG\njx7d8okAQBKjR48eMK0gM6u/pk0GwIBIBF0G0rqaWf01dTIwM7P+0bR9BuXaZvy6X+fXcdb7exy/\ndOlS9thjDwCeeOIJBg8ezNix6Yt+c+fOZejQoT29HIBp06YxY8YMtt12rW4x3zpmbtj7NAZA24rL\nez1GzdZEyySDehs9ejTz588HYObMmYwYMYKTTz55tWm6fmh60KDKDbDvfe97NY/TzKwavkzUzx55\n5BEmT57Mcccdx9SpU1m4cCHTp0+nvb2d7bffnjPOOOPVad/5zncyf/58Vq5cyahRo5gxYwY77rgj\nu+66K4sWLSpwLcxsoHEyqIEHHniAo48+mj//+c+MGzeOs846i3nz5nH33XczZ84cHnjggde95tln\nn+Xd7343d999N7vuuiuzZ88uIHIzG6icDGpgq622Yuedd371+RVXXMHUqVOZOnUqCxYsqJgMhg8f\nzr777gvATjvtREdHR73CNTNzn0EtrL/++q8+fvjhhznnnHOYO3cuo0aN4tBDD634fYHSDufBgwez\ncuXKusRqZgZOBjW3bNkyRo4cyQYbbMDChQu5/vrr2WeffYoOqzHNfLboCJpGR9EBWMtpmWTQqGV2\nU6dOZdKkSUyePJktt9yS3XbbreiQGpdLS62RDLAPJ03xG8jt7e1R/uM2CxYsYLvttisoomK0/Do7\nGVgjaYFkIOnOiGivZlp3IJuZmZOBmZk5GZiZGU4GZmZGC1UTWQtogQ47s2blZGCNw9VEa61txeX9\nNq9GLde22midZNDfJ5JePqX2xy2sAWbPns1+++3HpptuunbxmpmthdZJBnVWzS2sqzF79mymTp3q\nZGBmhXIyqIFLL72U888/n5deeol3vOMdnHfeeaxatYpp06Yxf/58IoLp06ezySabMH/+fA466CCG\nDx++Ri0KM7P+5GTQz+677z6uueYabr31VtZZZx2mT5/OlVdeyVZbbcWSJUu49957AXjmmWcYNWoU\n3/nOdzjvvPOYMmVKwZGb2UDmZNDPfvOb33DHHXfQ3p6+Af7iiy8yYcIE9t57bx566CFOPPFE9ttv\nP/baa6+CI21AriZaax1FB2BNq2bJQNIE4PvApsAqYFZEnCNpJnAssDhPempEXFurOOotIjjqqKM4\n88wzXzfunnvu4brrruPcc8/l6quvZtasWQVEaGb2erVsGawEPhsRd0kaCdwpaU4e962I+EYNl12Y\nPffckwMOOIATTzyRMWPGsHTpUp5//nmGDx/OsGHDOPDAA5k4cSLHHXccACNHjmT58uUFR90gWrG0\n1K0daxI1SwYRsRBYmB8vl7QAGFer5TXKm+4tb3kLp59+OnvuuSerVq1iyJAhXHjhhQwePJijjz6a\niEASX//61wGYNm0axxxzjDuQzaxQdbmFtaQ24GZgMvAfwJHAMmAeqfXwdE+v9y2sk5ZfZ7cMzPpV\nQ93CWtII4GrgpIhYBlwAbAVMIbUcvtnN66ZLmidp3uLFiytNYmZm/aSmyUDSEFIiuCwifgoQEU9G\nxCsRsQq4CHhbpddGxKyIaI+I9q5v9pqZWW3UsppIwMXAgog4u2T4Zrk/AeAjwH19XUbX9feBoBl+\nkW6t+ZKKWWFqWU20G3AYcK+k+XnYqcAhkqYAQSqL/mRfZj5s2DCWLl3K6NGjWz4hRARLly5l2LBh\nRYdiZi2qltVEfwQqnaX75TsF48ePp7Ozk4HSnzBs2DDGjx9fdBi11YodyGvCLSMrUNN+A3nIkCFM\nnDix6DDMzFqCf+nMzMycDMzMzMnAzMxo4j4Da0HuQDUrjFsGZmbmloE1kIFeWlqAthWXF7LcjrPe\nX8hyrXtuGZiZmZOBmZk5GZiZGU4GZmaGO5Ctkbi0tO46ig7AGoaTgTUOVxMVpt5VRa4majy+TGRm\nZk4GZmbmZGBmZjgZmJkZTgZmZoariayRuLS0MB1FB2CFczKwxuHS0roq6iZ13XG5abF8mcjMzJwM\nzMzMycDMzHAyMDMznAzMzAxXE1kjcWlpXXUUHYA1lJolA0kTgO8DmwKrgFkRcY6kjYEfAW2k4/Fj\nEfF0reKwJuLS0obRaGWn5VyG2v9qeZloJfDZiNgO2AU4XtIkYAbw24jYGvhtfm5mZgWqWTKIiIUR\ncVd+vBxYAIwDPgxcmie7FNi/VjGYmVl16tKBLKkNeCvwJ2CTiFgIKWEAb+jmNdMlzZM0b/HixfUI\n08xswKp5MpA0ArgaOCkillX7uoiYFRHtEdE+duzY2gVoZma1TQaShpASwWUR8dM8+ElJm+XxmwGL\nahmDmZn1rpbVRAIuBhZExNklo34BHAGclf//vFYxWJNxaWnD6Cg6AKu7Wn7PYDfgMOBeSfPzsFNJ\nSeAqSUcD/wAOrGEMTaNtxq+LDqFXHcM+XtsFOBmYFaZmySAi/giom9F71Gq5Zma25nw7CjMzczIw\nMzMnAzMzw8nAzMzwXUsbRnPceMvVPmatysmgxRRRotpvJacuLTUrjC8TmZmZk4GZmTkZmJkZTgZm\nZoY7kFtOMVVJ7vg1a3ZuGZiZmVsG1rN6lqq+rkTVpaZmdeOWgZmZORmYmZmTgZmZ4WRgZma4A9l6\nUd9SVXcYmxXFLQMzM6uuZSBpG+ACYJOImCxpB+BDEfHVmkZn/aaIu5l2qfqupi4lNStMtS2Di4Av\nAC8DRMQ9wMG1CsrMzOqr2mSwXkTMLRu2sr+DMTOzYlSbDJZI2goIAEkHAAtrFpWZmdVVtdVExwOz\ngDdL+ifwKPCJmkVlZmZ11WsykDQIaI+IPSWtDwyKiOW1D836U7G/seyOYbNG12syiIhVkk4AroqI\n56udsaTZwAeARRExOQ+bCRwLLM6TnRoR165x1A2qyIqdWum33zeuhquJzApTbZ/BHEknS5ogaeOu\nv15ecwmwT4Xh34qIKfmvZRKBmVkzq7bP4Kj8//iSYQFs2d0LIuJmSW19C8vMzOqpqmQQERP7cZkn\nSDocmAd8NiKerjSRpOnAdIAtttiiHxdvZmblqv0G8uGVhkfE99dweRcAZ5JaFWcC3+S1Vkf5vGeR\nKphob2+PNVyOmZmtgWovE+1c8ngYsAdwF7BGySAinux6LOki4Fdr8nozM6uNai8Tfab0uaQNgR+s\n6cIkbRYRXV9W+whw35rOo5EVW75ZK67wMRsI+noL6xeArXuaQNIVwO7AGEmdwOnA7pKmkC4TdQCf\n7OPyrZ80UjnsamWsLjM1q6tq+wx+Sb4VBakcdRLw455eExGHVBh88RpFZ2ZmdVFty+AbJY9XAn+P\niM4axGNmZgWo9ktn+0XE7/PfLRHRKenrNY3MzMzqptpk8L4Kw/btz0DMzKw4PV4mkvQp4NPAlpLu\nKRk1ErilloGZmVn99NZncDlwHfA1YEbJ8OUR8VTNorK6aaxyWFcQmRWlx2QQEc+S3qGHAEh6A+lL\nZyMkjYiIf9Q+RBswZm5YdAQ9altxedEh9JvG+hBgjaCqPgNJH5T0MOlHbX5P+o7AdTWMy8zM6qja\nDuSvArsAf8k3rdsD9xmYmbWMapPByxGxFBgkaVBE/A6YUsO4zMysjqr90tkzkkYAfwAuk7SI9OUz\nMzNrAdW2DD5Muh/RScD/AH8FPliroMzMrL6qvWvp85LeCGwdEZdKWg8YXNvQbMBp8JvTdRQdgFkN\nVXujumNJvzq2MbAVMA64kNSRbNY/6lha2kploo3EJavNq9rLRMcDuwHLACLiYeANtQrKzMzqq9pk\n8K+IeKnriaR1eO2W1mZm1uSqTQa/l3QqMFzS+0i/ZfDL2oVlZmb1VG0ymAEsBu4l/TrZtcAXaxWU\nmZnVV293Ld0iIv4REauAi/KfmZm1mN6qiX4GTAWQdHVE/HvtQ7IBq46lpR11W5JZc+gtGajk8Za1\nDMR60eB39OwPbSsud2miWUF66zOIbh6bmVkL6a1lsKOkZaQWwvD8mPw8ImKDmkZnZmZ10duP2/iW\nE2ZmA0C1paVmZtbCqr2FtRWtwW/i1h86ig7AbACrWctA0mxJiyTdVzJsY0lzJD2c/29Uq+WbmVn1\natkyuAQ4D/h+ybAZwG8j4ixJM/LzU2oYgzWTJiyf9d1PG4/Lk/umZi2DiLgZeKps8IeBS/PjS4H9\na7V8MzOrXr07kDeJiIUA+b9vg21m1gAatppI0nRJ8yTNW7x4cdHhmJm1tHongyclbQaQ/y/qbsKI\nmBUR7RHRPnbs2LoFaGY2ENW7tPQXwBHAWfn/z+u8fGtkTVg+21F0AGb9pJalpVcAtwHbSuqUdDQp\nCbxP0sPA+/JzMzMrWM1aBhFxSDej9qjVMitpm/HrNZq+Y9jHaxSJ9aoJWwZmraJhO5DNzKx+nAzM\nzMzJwMzMnAzMzIwBcNfSNb9PiTsxzWzgccvAzMxav2VgNdafdxp1aalZYdwyMDMzJwMzM3MyMDMz\nnAzMzAx3INvacqevWUtwMrDG0YS/gWz9y78p/Xr1+k1nXyYyMzMnAzMzczIwMzOcDMzMDCcDMzPD\n1UTWSFymOuB1FB3AAOZkYI3DpaV1MxBLOOtVotmsfJnIzMycDMzMzMnAzMxwMjAzM5wMzMwMVxNZ\nI3Fpad10FB2ANZxCkoGkDmA58AqwMiLai4jDGkwPpaX9UQrp0kKz7hXZMnhPRCwpcPlmZpa5z8DM\nzApLBgHcIOlOSdMrTSBpuqR5kuYtXry4zuGZmQ0sRSWD3SJiKrAvcLykd5VPEBGzIqI9ItrHjh1b\n/wjNzAaQQpJBRDye/y8CrgHeVkQcZmaW1L0DWdL6wKCIWJ4f7wWcUe84rAH1UFraUb8ozAakIqqJ\nNgGukdS1/Msj4n8KiMMqKfLOof6egVlh6p4MIuJvwI71Xq6ZmXXPpaVmZuZkYGZmTgZmZoZvVGfl\n3IlrNiC5ZWBmZm4ZWAMpsqy1gVW6Y6vvwGr9zS0DMzNzMjAzMycDMzPDycDMzHAHsjUSl7VW1FF0\nADYguGVgZmZuGVgDaYHS0kploF1cDmqNzC0DMzNzMjAzMycDMzPDycDMzHAHsjWSFigt7Sg6ALM+\ncsvAzMzcMrAG0mClpT2ViTYjl7ZaT9wyMDMzJwMzM3MyMDMznAzMzAx3IFsjabDS0o6iAzCro0KS\ngaR9gHOAwcB3I+KsIuKwBtNg1UTVKq86ctWONaO6XyaSNBg4H9gXmAQcImlSveMwM7PXFNFn8Dbg\nkYj4W0S8BFwJfLiAOMzMLCsiGYwDHit53pmHrUbSdEnzJM1bvHhx3YIzMxuIikgGqjAsXjcgYlZE\ntEdE+9ixY+sQlpnZwFVEMugEJpQ8Hw88XkAcZmaWFVFNdAewtaSJwD+Bg4GPFxCHNZoGKy2tVkfR\nAZj1g7ong4hYKekE4HpSaensiLi/3nGYmdlrCvmeQURcC1xbxLLNzOz1fDsKMzNzMjAzMycDMzPD\nycDMzHAyMDMznAzMzAwnAzMzAxTxutsCNRxJi4G/lwwaAywpKJx687q2noGynjBw1rVR1/ONEVHV\nzd2aIhmUkzQvItqLjqMevK6tZ6CsJwycdW2F9fRlIjMzczIwM7PmTQazig6gjryurWegrCcMnHVt\n+vVsyj4DMzPrX83aMjAzs37kZGBmZs2bDCT9P0kPSrpH0jWSRhUdU61IOlDS/ZJWSWrq8rVKJO0j\n6SFJj0iaUXQ8tSJptqRFku4rOpZakjRB0u8kLcjH7YlFx1QrkoZJmivp7ryuXyk6pr5q2mQAzAEm\nR8QOwF+ALxQcTy3dB3wUuLnoQPqbpMHA+cC+wCTgEEmTio2qZi4B9ik6iDpYCXw2IrYDdgGOb+F9\n+i/gvRGxIzAF2EfSLgXH1CdNmwwi4oaIWJmf3g6MLzKeWoqIBRHxUNFx1MjbgEci4m8R8RJwJfDh\ngmOqiYi4GXiq6DhqLSIWRsRd+fFyYAEwrtioaiOS5/LTIfmvKatymjYZlDkKuK7oIKxPxgGPlTzv\npEVPHAORpDbgrcCfio2kdiQNljQfWATMiYimXNdCfgO5WpJ+A2xaYdRpEfHzPM1ppGbpZfWMrb9V\ns64tShWGNeUnK1udpBHA1cBJEbGs6HhqJSJeAabkfstrJE2OiKbrF2roZBARe/Y0XtIRwAeAPaLJ\nvzDR27q2sE5gQsnz8cDjBcVi/UTSEFIiuCwiflp0PPUQEc9IuonUL9R0yaBpLxNJ2gc4BfhQRLxQ\ndDzWZ3cAW0uaKGkocDDwi4JjsrUgScDFwIKIOLvoeGpJ0tiuSkZJw4E9gQeLjapvmjYZAOcBI4E5\nkuZLurDogGpF0kckdQK7Ar+WdH3RMfWXXARwAnA9qaPxqoi4v9ioakPSFcBtwLaSOiUdXXRMNbIb\ncBjw3vzenC9pv6KDqpHNgN9Juof0wWZORPyq4Jj6xLejMDOzpm4ZmJlZP3EyMDMzJwMzM3MyMDMz\nnAzMzIwG/9KZ2dqQ9Apwb8mg/SOio6BwzBqaS0utZUl6LiJG9DB+nZKbHZoNaL5MZAOKpCMl/VjS\nL4Eb8rDPSboj/zbGV0qmPS3/zsJvJF0h6eQ8/Kau35WQNEZSR348OP/ORte8PpmH755f85P8GxyX\n5W/pImlnSbfm++HPlTRS0h8kTSmJ4xZJO9RrG9nA5MtE1sqG57tJAjwaER/Jj3cFdoiIpyTtBWxN\nupW2gF9IehfwPOnWGG8lvU93G+AGAAABwUlEQVTuAu7sZXlHA89GxM6S1gVukXRDHvdWYHvSfZdu\nAXaTNBf4EXBQRNwhaQPgReC7wJHASZK2AdaNiHvWakuY9cLJwFrZixExpcLwORHR9bsCe+W/P+fn\nI0jJYSRwTdd9ryRVc7+kvYAdJB2Qn2+Y5/USMDciOvO85gNtwLPAwoi4A6Drzp6Sfgx8SdLnSLdn\nv6TaFTbrKycDG4ieL3ks4GsR8d+lE0g6ie5vpb2S1y6xDiub12ciYrV7R0nanfSLWF1eIb33VGkZ\nEfGCpDmkH/n5GNByP3Vqjcd9BjbQXQ8cle+9j6Rxkt5A+onRj0gaLmkk8MGS13QAO+XHB5TN61P5\n9s1I2kbS+j0s+0Fgc0k75+lHSur6gPZd4FzgjpJWjFnNuGVgA1pE3CBpO+C23Kf7HHBoRNwl6UfA\nfODvwB9KXvYN4CpJhwE3lgz/Lunyz125g3gxsH8Py35J0kHAd/Ltj18k3QL5uYi4U9Iy4Hv9tKpm\nPXJpqVkVJM0knaS/UaflbQ7cBLw5IlbVY5k2sPkykVmDkXQ46TeDT3MisHpxy8DMzNwyMDMzJwMz\nM8PJwMzMcDIwMzOcDMzMDPj/NZ7vvDYnzPEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f34c14cd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef2 = logReg4.coef_[0]\n",
    "plt.barh(list(range(coef1.shape[0])), coef1, align='center', label='Train')\n",
    "plt.barh(list(range(coef2.shape[0])), coef2, align='center', label='Test')\n",
    "plt.legend()\n",
    "plt.title(\"Logistic Regression Combined Model Feature Importance\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer = pd.read_csv('C:\\JHU_Python\\data/wdbc.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = (cancer[1]=='M').astype(int) #this creates the Y depended classification variable based on the M \"malignant\"\n",
    "X = cancer[[*range(2,31)]] #this creates a matrix of X variables based on the columns between columns 2 and 31. I will train test these variables againsts Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sklearn.preprocessing.MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pat\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X, Y, train_size=.7) # 70/30 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer_svm1 = svm.SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_svm1.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       243\n",
      "          1       0.99      0.96      0.98       155\n",
      "\n",
      "avg / total       0.98      0.98      0.98       398\n",
      "\n",
      "[[242   1]\n",
      " [  6 149]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train1, cancer_svm1.predict(x_train1))) #train statisitics linear\n",
    "print(confusion_matrix(y_train1, cancer_svm1.predict(x_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer_svm2 = svm.SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_svm2.fit(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       114\n",
      "          1       1.00      0.91      0.95        57\n",
      "\n",
      "avg / total       0.97      0.97      0.97       171\n",
      "\n",
      "[[114   0]\n",
      " [  5  52]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, cancer_svm2.predict(x_test1))) #test statisitics linear\n",
    "print(confusion_matrix(y_test1, cancer_svm2.predict(x_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial basis function kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer_svm_rbf1 = svm.SVC(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_svm_rbf1.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       243\n",
      "          1       1.00      0.87      0.93       155\n",
      "\n",
      "avg / total       0.95      0.95      0.95       398\n",
      "\n",
      "[[243   0]\n",
      " [ 20 135]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train1, cancer_svm_rbf1.predict(x_train1))) #train statisitics rbf\n",
    "print(confusion_matrix(y_train1, cancer_svm_rbf1.predict(x_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer_svm_rbf2 = svm.SVC(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_svm_rbf2.fit(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       114\n",
      "          1       1.00      0.79      0.88        57\n",
      "\n",
      "avg / total       0.94      0.93      0.93       171\n",
      "\n",
      "[[114   0]\n",
      " [ 12  45]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, cancer_svm_rbf2.predict(x_test1))) #test statistics rbf\n",
    "print(confusion_matrix(y_test1, cancer_svm_rbf2.predict(x_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression C=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logReg1 = LogisticRegression(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg1.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1 = logReg1.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       243\n",
      "          1       1.00      0.91      0.95       155\n",
      "\n",
      "avg / total       0.97      0.96      0.96       398\n",
      "\n",
      "[[243   0]\n",
      " [ 14 141]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train1, logReg1.predict(x_train1))) #train statisitics logisitic reg\n",
    "print(confusion_matrix(y_train1, logReg1.predict(x_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logReg2 = LogisticRegression(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg2.fit(x_test1, y_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96       114\n",
      "          1       0.98      0.84      0.91        57\n",
      "\n",
      "avg / total       0.94      0.94      0.94       171\n",
      "\n",
      "[[113   1]\n",
      " [  9  48]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, logReg2.predict(x_test1))) #train statisitics rbf\n",
    "print(confusion_matrix(y_test1, logReg2.predict(x_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression C=3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logReg3 = LogisticRegression(C=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg3.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logReg4 = LogisticRegression(C=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg4.fit(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       243\n",
      "          1       0.99      0.95      0.97       155\n",
      "\n",
      "avg / total       0.98      0.98      0.98       398\n",
      "\n",
      "[[241   2]\n",
      " [  7 148]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train1, logReg3.predict(x_train1))) #train statisitics\n",
    "print(confusion_matrix(y_train1, logReg3.predict(x_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       114\n",
      "          1       1.00      0.91      0.95        57\n",
      "\n",
      "avg / total       0.97      0.97      0.97       171\n",
      "\n",
      "[[114   0]\n",
      " [  5  52]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, logReg4.predict(x_test1))) \n",
    "print(confusion_matrix(y_test1, logReg4.predict(x_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Neariest Neighbors n-neighbors=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "class1=classifier.fit(x_train1, y_train1)\n",
    "y_pred = classifier.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98       243\n",
      "          1       0.98      0.96      0.97       155\n",
      "\n",
      "avg / total       0.98      0.98      0.98       398\n",
      "\n",
      "[[240   3]\n",
      " [  6 149]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train1, classifier.predict(x_train1))) #train statisitics\n",
    "print(confusion_matrix(y_train1, classifier.predict(x_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       114\n",
      "          1       1.00      0.95      0.97        57\n",
      "\n",
      "avg / total       0.98      0.98      0.98       171\n",
      "\n",
      "[[114   0]\n",
      " [  3  54]]\n"
     ]
    }
   ],
   "source": [
    "classifier2 = KNeighborsClassifier(n_neighbors=5)\n",
    "class2 = classifier2.fit(x_test1, y_test1)\n",
    "print(classification_report(y_test1, classifier2.predict(x_test1))) #test statisitics\n",
    "print(confusion_matrix(y_test1, classifier2.predict(x_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Neariest Neighbors n-neighbors=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       243\n",
      "          1       0.99      0.95      0.97       155\n",
      "\n",
      "avg / total       0.98      0.98      0.98       398\n",
      "\n",
      "[[242   1]\n",
      " [  8 147]]\n"
     ]
    }
   ],
   "source": [
    "classifier3 = KNeighborsClassifier(n_neighbors=10)\n",
    "classifier3.fit(x_train1, y_train1)\n",
    "y_pred = classifier3.predict(x_test1)\n",
    "print(classification_report(y_train1, classifier3.predict(x_train1))) #train statisitics\n",
    "print(confusion_matrix(y_train1, classifier3.predict(x_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       114\n",
      "          1       1.00      0.88      0.93        57\n",
      "\n",
      "avg / total       0.96      0.96      0.96       171\n",
      "\n",
      "[[114   0]\n",
      " [  7  50]]\n"
     ]
    }
   ],
   "source": [
    "classifier4 = KNeighborsClassifier(n_neighbors=10)\n",
    "classifier4.fit(x_test1, y_test1)\n",
    "\n",
    "print(classification_report(y_test1, classifier4.predict(x_test1))) #test statisitics\n",
    "print(confusion_matrix(y_test1, classifier4.predict(x_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Neariest Neighbors n-neighbors=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98       243\n",
      "          1       0.98      0.94      0.96       155\n",
      "\n",
      "avg / total       0.97      0.97      0.97       398\n",
      "\n",
      "[[240   3]\n",
      " [  9 146]]\n"
     ]
    }
   ],
   "source": [
    "classifier5 = KNeighborsClassifier(n_neighbors=15)\n",
    "classifier5.fit(x_train1, y_train1)\n",
    "\n",
    "print(classification_report(y_train1, classifier5.predict(x_train1))) #train statisitics\n",
    "print(confusion_matrix(y_train1, classifier5.predict(x_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       114\n",
      "          1       1.00      0.88      0.93        57\n",
      "\n",
      "avg / total       0.96      0.96      0.96       171\n",
      "\n",
      "[[114   0]\n",
      " [  7  50]]\n"
     ]
    }
   ],
   "source": [
    "classifier6 = KNeighborsClassifier(n_neighbors=15)\n",
    "classifier6.fit(x_test1, y_test1)\n",
    "\n",
    "print(classification_report(y_test1, classifier6.predict(x_test1))) #train statisitics\n",
    "print(confusion_matrix(y_test1, classifier6.predict(x_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['SVM_Linear','SVM_rbf','Logistic_Regression_C_3','Logistic_Regression_C_3','KNN_5','KNN_10','KNN_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingdf = pd.read_csv('C:\\JHU_Python\\data/trainingdata.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_Linear</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_Regression C_1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_Regression C_3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN_10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN_15</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Precision  Recall  F1 Score\n",
       "0               SVM_Linear       0.99    0.96      0.98\n",
       "1                  SVM_rbf       1.00    0.87      0.93\n",
       "2  Logistic_Regression C_1       1.00    0.91      0.95\n",
       "3  Logistic_Regression C_3       0.99    0.95      0.97\n",
       "4                    KNN_5       0.98    0.96      0.97\n",
       "5                   KNN_10       0.99    0.95      0.97\n",
       "6                   KNN_15       0.98    0.94      0.96"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1 summarizes the metrics for seven classification models that attempt to predict breast cancer. The metric parameters recorded were precision, recall, and F1 score. The models implemented a 70-30 train/test split and the above table represents metrics for the training data. Additionally the data has been rescaled using the MinMaxScaler algorithm to transform the independent X variables values to 0 to 1. Values classified as \"1\" were classified as malignent as represented by the Y variable. Both logisitic regression C=3.0 and KNN with 5 nearest neighbors performed very well but I choose logisitic regression as the best training and test model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('C:\\JHU_Python\\data/testdata.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_Linear</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_Regression C_1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_Regression C_3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN_10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN_15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Precision  Recall  F1 Score\n",
       "0               SVM_Linear       1.00    0.91      0.95\n",
       "1                  SVM_rbf       1.00    0.79      0.88\n",
       "2  Logistic_Regression C_1       0.98    0.84      0.91\n",
       "3  Logistic_Regression C_3       1.00    0.91      0.95\n",
       "4                    KNN_5       1.00    0.95      0.97\n",
       "5                   KNN_10       1.00    0.88      0.93\n",
       "6                   KNN_15       1.00    0.88      0.93"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 2 summarizes the metrics for seven classification models that attempt to predict breast cancer. The metric parameters recorded were precision, recall, and F1 score. The models implemented a 70-30 train/test split. The above table represents metrics for the 30% test data. Linear SVM, logisitic regression, and KNN_5 performed very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAEWCAYAAAC66pSsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBOxmZlZQf8f8EVAfa2SeZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f34bcf6550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEWCAYAAAAD/hLkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMys1v4/wr+o7uUWHIwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f34c29f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef2 = logReg4.coef_[0]\n",
    "plt.barh(list(range(coef1.shape[0])), coef1, align='center')\n",
    "plt.barh(list(range(coef2.shape[0])), coef2, align='center')\n",
    "plt.title(\"Logistic Regression Test Model Feature Importance (Test Size = 30%)\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.880</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>...</td>\n",
       "      <td>17.060</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>...</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>...</td>\n",
       "      <td>20.420</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>...</td>\n",
       "      <td>16.840</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>...</td>\n",
       "      <td>15.030</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84799002</td>\n",
       "      <td>M</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>...</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>848406</td>\n",
       "      <td>M</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>...</td>\n",
       "      <td>19.070</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84862001</td>\n",
       "      <td>M</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>849014</td>\n",
       "      <td>M</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>...</td>\n",
       "      <td>27.320</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.066640</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8511133</td>\n",
       "      <td>M</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>...</td>\n",
       "      <td>18.070</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>851509</td>\n",
       "      <td>M</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>...</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>852552</td>\n",
       "      <td>M</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>...</td>\n",
       "      <td>26.460</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>852631</td>\n",
       "      <td>M</td>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>...</td>\n",
       "      <td>22.250</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>852763</td>\n",
       "      <td>M</td>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>...</td>\n",
       "      <td>17.620</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>852781</td>\n",
       "      <td>M</td>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>...</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>852973</td>\n",
       "      <td>M</td>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>...</td>\n",
       "      <td>20.270</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>853201</td>\n",
       "      <td>M</td>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>921362</td>\n",
       "      <td>B</td>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>...</td>\n",
       "      <td>8.678</td>\n",
       "      <td>31.89</td>\n",
       "      <td>54.49</td>\n",
       "      <td>223.6</td>\n",
       "      <td>0.15960</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.10660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>921385</td>\n",
       "      <td>B</td>\n",
       "      <td>11.540</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>...</td>\n",
       "      <td>12.260</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.21180</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>921386</td>\n",
       "      <td>B</td>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>...</td>\n",
       "      <td>16.220</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>921644</td>\n",
       "      <td>B</td>\n",
       "      <td>14.740</td>\n",
       "      <td>25.42</td>\n",
       "      <td>94.70</td>\n",
       "      <td>668.6</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>...</td>\n",
       "      <td>16.510</td>\n",
       "      <td>32.29</td>\n",
       "      <td>107.40</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.06956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>922296</td>\n",
       "      <td>B</td>\n",
       "      <td>13.210</td>\n",
       "      <td>28.06</td>\n",
       "      <td>84.88</td>\n",
       "      <td>538.4</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>...</td>\n",
       "      <td>14.370</td>\n",
       "      <td>37.17</td>\n",
       "      <td>92.48</td>\n",
       "      <td>629.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.07958</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.06443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>922297</td>\n",
       "      <td>B</td>\n",
       "      <td>13.870</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.77</td>\n",
       "      <td>584.8</td>\n",
       "      <td>0.09578</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>...</td>\n",
       "      <td>15.050</td>\n",
       "      <td>24.75</td>\n",
       "      <td>99.17</td>\n",
       "      <td>688.6</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>0.20370</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.06845</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.08492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>922576</td>\n",
       "      <td>B</td>\n",
       "      <td>13.620</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.350</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>922577</td>\n",
       "      <td>B</td>\n",
       "      <td>10.320</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>...</td>\n",
       "      <td>11.250</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>922840</td>\n",
       "      <td>B</td>\n",
       "      <td>10.260</td>\n",
       "      <td>16.58</td>\n",
       "      <td>65.85</td>\n",
       "      <td>320.8</td>\n",
       "      <td>0.08877</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.830</td>\n",
       "      <td>22.04</td>\n",
       "      <td>71.08</td>\n",
       "      <td>357.4</td>\n",
       "      <td>0.14610</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.17830</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.09479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>923169</td>\n",
       "      <td>B</td>\n",
       "      <td>9.683</td>\n",
       "      <td>19.34</td>\n",
       "      <td>61.05</td>\n",
       "      <td>285.7</td>\n",
       "      <td>0.08491</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930</td>\n",
       "      <td>25.59</td>\n",
       "      <td>69.10</td>\n",
       "      <td>364.2</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.07920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>923465</td>\n",
       "      <td>B</td>\n",
       "      <td>10.820</td>\n",
       "      <td>24.21</td>\n",
       "      <td>68.89</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>...</td>\n",
       "      <td>13.030</td>\n",
       "      <td>31.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.07626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>923748</td>\n",
       "      <td>B</td>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.660</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>923780</td>\n",
       "      <td>B</td>\n",
       "      <td>11.130</td>\n",
       "      <td>22.44</td>\n",
       "      <td>71.49</td>\n",
       "      <td>378.4</td>\n",
       "      <td>0.09566</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020</td>\n",
       "      <td>28.26</td>\n",
       "      <td>77.80</td>\n",
       "      <td>436.6</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.08032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>924084</td>\n",
       "      <td>B</td>\n",
       "      <td>12.770</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>...</td>\n",
       "      <td>13.870</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>924342</td>\n",
       "      <td>B</td>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>...</td>\n",
       "      <td>9.845</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>924632</td>\n",
       "      <td>B</td>\n",
       "      <td>12.880</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>924934</td>\n",
       "      <td>B</td>\n",
       "      <td>10.290</td>\n",
       "      <td>27.61</td>\n",
       "      <td>65.67</td>\n",
       "      <td>321.4</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.07658</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.840</td>\n",
       "      <td>34.91</td>\n",
       "      <td>69.57</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.13840</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.09127</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>924964</td>\n",
       "      <td>B</td>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>...</td>\n",
       "      <td>10.650</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>925236</td>\n",
       "      <td>B</td>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.490</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>925277</td>\n",
       "      <td>B</td>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>...</td>\n",
       "      <td>15.480</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>925291</td>\n",
       "      <td>B</td>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>925292</td>\n",
       "      <td>B</td>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>925311</td>\n",
       "      <td>B</td>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>925622</td>\n",
       "      <td>M</td>\n",
       "      <td>15.220</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>...</td>\n",
       "      <td>17.520</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>926125</td>\n",
       "      <td>M</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1       2      3       4       5        6        7         8   \\\n",
       "0      842302  M  17.990  10.38  122.80  1001.0  0.11840  0.27760  0.300100   \n",
       "1      842517  M  20.570  17.77  132.90  1326.0  0.08474  0.07864  0.086900   \n",
       "2    84300903  M  19.690  21.25  130.00  1203.0  0.10960  0.15990  0.197400   \n",
       "3    84348301  M  11.420  20.38   77.58   386.1  0.14250  0.28390  0.241400   \n",
       "4    84358402  M  20.290  14.34  135.10  1297.0  0.10030  0.13280  0.198000   \n",
       "5      843786  M  12.450  15.70   82.57   477.1  0.12780  0.17000  0.157800   \n",
       "6      844359  M  18.250  19.98  119.60  1040.0  0.09463  0.10900  0.112700   \n",
       "7    84458202  M  13.710  20.83   90.20   577.9  0.11890  0.16450  0.093660   \n",
       "8      844981  M  13.000  21.82   87.50   519.8  0.12730  0.19320  0.185900   \n",
       "9    84501001  M  12.460  24.04   83.97   475.9  0.11860  0.23960  0.227300   \n",
       "10     845636  M  16.020  23.24  102.70   797.8  0.08206  0.06669  0.032990   \n",
       "11   84610002  M  15.780  17.89  103.60   781.0  0.09710  0.12920  0.099540   \n",
       "12     846226  M  19.170  24.80  132.40  1123.0  0.09740  0.24580  0.206500   \n",
       "13     846381  M  15.850  23.95  103.70   782.7  0.08401  0.10020  0.099380   \n",
       "14   84667401  M  13.730  22.61   93.60   578.3  0.11310  0.22930  0.212800   \n",
       "15   84799002  M  14.540  27.54   96.73   658.8  0.11390  0.15950  0.163900   \n",
       "16     848406  M  14.680  20.13   94.74   684.5  0.09867  0.07200  0.073950   \n",
       "17   84862001  M  16.130  20.68  108.10   798.8  0.11700  0.20220  0.172200   \n",
       "18     849014  M  19.810  22.15  130.00  1260.0  0.09831  0.10270  0.147900   \n",
       "19    8510426  B  13.540  14.36   87.46   566.3  0.09779  0.08129  0.066640   \n",
       "20    8510653  B  13.080  15.71   85.63   520.0  0.10750  0.12700  0.045680   \n",
       "21    8510824  B   9.504  12.44   60.34   273.9  0.10240  0.06492  0.029560   \n",
       "22    8511133  M  15.340  14.26  102.50   704.4  0.10730  0.21350  0.207700   \n",
       "23     851509  M  21.160  23.04  137.20  1404.0  0.09428  0.10220  0.109700   \n",
       "24     852552  M  16.650  21.38  110.00   904.6  0.11210  0.14570  0.152500   \n",
       "25     852631  M  17.140  16.40  116.00   912.7  0.11860  0.22760  0.222900   \n",
       "26     852763  M  14.580  21.53   97.41   644.8  0.10540  0.18680  0.142500   \n",
       "27     852781  M  18.610  20.25  122.10  1094.0  0.09440  0.10660  0.149000   \n",
       "28     852973  M  15.300  25.27  102.40   732.4  0.10820  0.16970  0.168300   \n",
       "29     853201  M  17.570  15.05  115.00   955.1  0.09847  0.11570  0.098750   \n",
       "..        ... ..     ...    ...     ...     ...      ...      ...       ...   \n",
       "539    921362  B   7.691  25.44   48.34   170.4  0.08668  0.11990  0.092520   \n",
       "540    921385  B  11.540  14.44   74.65   402.9  0.09984  0.11200  0.067370   \n",
       "541    921386  B  14.470  24.99   95.81   656.4  0.08837  0.12300  0.100900   \n",
       "542    921644  B  14.740  25.42   94.70   668.6  0.08275  0.07214  0.041050   \n",
       "543    922296  B  13.210  28.06   84.88   538.4  0.08671  0.06877  0.029870   \n",
       "544    922297  B  13.870  20.70   89.77   584.8  0.09578  0.10180  0.036880   \n",
       "545    922576  B  13.620  23.23   87.19   573.2  0.09246  0.06747  0.029740   \n",
       "546    922577  B  10.320  16.35   65.31   324.9  0.09434  0.04994  0.010120   \n",
       "547    922840  B  10.260  16.58   65.85   320.8  0.08877  0.08066  0.043580   \n",
       "548    923169  B   9.683  19.34   61.05   285.7  0.08491  0.05030  0.023370   \n",
       "549    923465  B  10.820  24.21   68.89   361.6  0.08192  0.06602  0.015480   \n",
       "550    923748  B  10.860  21.48   68.51   360.5  0.07431  0.04227  0.000000   \n",
       "551    923780  B  11.130  22.44   71.49   378.4  0.09566  0.08194  0.048240   \n",
       "552    924084  B  12.770  29.43   81.35   507.9  0.08276  0.04234  0.019970   \n",
       "553    924342  B   9.333  21.94   59.01   264.0  0.09240  0.05605  0.039960   \n",
       "554    924632  B  12.880  28.92   82.50   514.3  0.08123  0.05824  0.061950   \n",
       "555    924934  B  10.290  27.61   65.67   321.4  0.09030  0.07658  0.059990   \n",
       "556    924964  B  10.160  19.59   64.73   311.7  0.10030  0.07504  0.005025   \n",
       "557    925236  B   9.423  27.88   59.26   271.3  0.08123  0.04971  0.000000   \n",
       "558    925277  B  14.590  22.68   96.39   657.1  0.08473  0.13300  0.102900   \n",
       "559    925291  B  11.510  23.93   74.52   403.5  0.09261  0.10210  0.111200   \n",
       "560    925292  B  14.050  27.15   91.38   600.4  0.09929  0.11260  0.044620   \n",
       "561    925311  B  11.200  29.37   70.67   386.0  0.07449  0.03558  0.000000   \n",
       "562    925622  M  15.220  30.62  103.40   716.9  0.10480  0.20870  0.255000   \n",
       "563    926125  M  20.920  25.09  143.00  1347.0  0.10990  0.22360  0.317400   \n",
       "564    926424  M  21.560  22.39  142.00  1479.0  0.11100  0.11590  0.243900   \n",
       "565    926682  M  20.130  28.25  131.20  1261.0  0.09780  0.10340  0.144000   \n",
       "566    926954  M  16.600  28.08  108.30   858.1  0.08455  0.10230  0.092510   \n",
       "567    927241  M  20.600  29.33  140.10  1265.0  0.11780  0.27700  0.351400   \n",
       "568     92751  B   7.760  24.54   47.92   181.0  0.05263  0.04362  0.000000   \n",
       "\n",
       "           9    ...         22     23      24      25       26       27  \\\n",
       "0    0.147100   ...     25.380  17.33  184.60  2019.0  0.16220  0.66560   \n",
       "1    0.070170   ...     24.990  23.41  158.80  1956.0  0.12380  0.18660   \n",
       "2    0.127900   ...     23.570  25.53  152.50  1709.0  0.14440  0.42450   \n",
       "3    0.105200   ...     14.910  26.50   98.87   567.7  0.20980  0.86630   \n",
       "4    0.104300   ...     22.540  16.67  152.20  1575.0  0.13740  0.20500   \n",
       "5    0.080890   ...     15.470  23.75  103.40   741.6  0.17910  0.52490   \n",
       "6    0.074000   ...     22.880  27.66  153.20  1606.0  0.14420  0.25760   \n",
       "7    0.059850   ...     17.060  28.14  110.60   897.0  0.16540  0.36820   \n",
       "8    0.093530   ...     15.490  30.73  106.20   739.3  0.17030  0.54010   \n",
       "9    0.085430   ...     15.090  40.68   97.65   711.4  0.18530  1.05800   \n",
       "10   0.033230   ...     19.190  33.88  123.80  1150.0  0.11810  0.15510   \n",
       "11   0.066060   ...     20.420  27.28  136.50  1299.0  0.13960  0.56090   \n",
       "12   0.111800   ...     20.960  29.94  151.70  1332.0  0.10370  0.39030   \n",
       "13   0.053640   ...     16.840  27.66  112.00   876.5  0.11310  0.19240   \n",
       "14   0.080250   ...     15.030  32.01  108.80   697.7  0.16510  0.77250   \n",
       "15   0.073640   ...     17.460  37.13  124.10   943.2  0.16780  0.65770   \n",
       "16   0.052590   ...     19.070  30.88  123.40  1138.0  0.14640  0.18710   \n",
       "17   0.102800   ...     20.960  31.48  136.80  1315.0  0.17890  0.42330   \n",
       "18   0.094980   ...     27.320  30.88  186.80  2398.0  0.15120  0.31500   \n",
       "19   0.047810   ...     15.110  19.26   99.70   711.2  0.14400  0.17730   \n",
       "20   0.031100   ...     14.500  20.49   96.09   630.5  0.13120  0.27760   \n",
       "21   0.020760   ...     10.230  15.66   65.13   314.9  0.13240  0.11480   \n",
       "22   0.097560   ...     18.070  19.08  125.10   980.9  0.13900  0.59540   \n",
       "23   0.086320   ...     29.170  35.59  188.00  2615.0  0.14010  0.26000   \n",
       "24   0.091700   ...     26.460  31.56  177.00  2215.0  0.18050  0.35780   \n",
       "25   0.140100   ...     22.250  21.40  152.40  1461.0  0.15450  0.39490   \n",
       "26   0.087830   ...     17.620  33.21  122.40   896.9  0.15250  0.66430   \n",
       "27   0.077310   ...     21.310  27.26  139.90  1403.0  0.13380  0.21170   \n",
       "28   0.087510   ...     20.270  36.71  149.30  1269.0  0.16410  0.61100   \n",
       "29   0.079530   ...     20.010  19.52  134.90  1227.0  0.12550  0.28120   \n",
       "..        ...   ...        ...    ...     ...     ...      ...      ...   \n",
       "539  0.013640   ...      8.678  31.89   54.49   223.6  0.15960  0.30640   \n",
       "540  0.025940   ...     12.260  19.68   78.78   457.8  0.13450  0.21180   \n",
       "541  0.038900   ...     16.220  31.73  113.50   808.9  0.13400  0.42020   \n",
       "542  0.030270   ...     16.510  32.29  107.40   826.4  0.10600  0.13760   \n",
       "543  0.032750   ...     14.370  37.17   92.48   629.6  0.10720  0.13810   \n",
       "544  0.023690   ...     15.050  24.75   99.17   688.6  0.12640  0.20370   \n",
       "545  0.024430   ...     15.350  29.09   97.58   729.8  0.12160  0.15170   \n",
       "546  0.005495   ...     11.250  21.77   71.12   384.9  0.12850  0.08842   \n",
       "547  0.024380   ...     10.830  22.04   71.08   357.4  0.14610  0.22460   \n",
       "548  0.009615   ...     10.930  25.59   69.10   364.2  0.11990  0.09546   \n",
       "549  0.008160   ...     13.030  31.45   83.90   505.6  0.12040  0.16330   \n",
       "550  0.000000   ...     11.660  24.77   74.08   412.3  0.10010  0.07348   \n",
       "551  0.022570   ...     12.020  28.26   77.80   436.6  0.10870  0.17820   \n",
       "552  0.014990   ...     13.870  36.00   88.10   594.7  0.12340  0.10640   \n",
       "553  0.012820   ...      9.845  25.05   62.86   295.8  0.11030  0.08298   \n",
       "554  0.023430   ...     13.890  35.74   88.84   595.7  0.12270  0.16200   \n",
       "555  0.027380   ...     10.840  34.91   69.57   357.6  0.13840  0.17100   \n",
       "556  0.011160   ...     10.650  22.88   67.88   347.3  0.12650  0.12000   \n",
       "557  0.000000   ...     10.490  34.24   66.50   330.6  0.10730  0.07158   \n",
       "558  0.037360   ...     15.480  27.27  105.90   733.5  0.10260  0.31710   \n",
       "559  0.041050   ...     12.480  37.16   82.28   474.2  0.12980  0.25170   \n",
       "560  0.043040   ...     15.300  33.17  100.20   706.7  0.12410  0.22640   \n",
       "561  0.000000   ...     11.920  38.30   75.19   439.6  0.09267  0.05494   \n",
       "562  0.094290   ...     17.520  42.79  128.70   915.0  0.14170  0.79170   \n",
       "563  0.147400   ...     24.290  29.41  179.10  1819.0  0.14070  0.41860   \n",
       "564  0.138900   ...     25.450  26.40  166.10  2027.0  0.14100  0.21130   \n",
       "565  0.097910   ...     23.690  38.25  155.00  1731.0  0.11660  0.19220   \n",
       "566  0.053020   ...     18.980  34.12  126.70  1124.0  0.11390  0.30940   \n",
       "567  0.152000   ...     25.740  39.42  184.60  1821.0  0.16500  0.86810   \n",
       "568  0.000000   ...      9.456  30.37   59.16   268.6  0.08996  0.06444   \n",
       "\n",
       "          28       29      30       31  \n",
       "0    0.71190  0.26540  0.4601  0.11890  \n",
       "1    0.24160  0.18600  0.2750  0.08902  \n",
       "2    0.45040  0.24300  0.3613  0.08758  \n",
       "3    0.68690  0.25750  0.6638  0.17300  \n",
       "4    0.40000  0.16250  0.2364  0.07678  \n",
       "5    0.53550  0.17410  0.3985  0.12440  \n",
       "6    0.37840  0.19320  0.3063  0.08368  \n",
       "7    0.26780  0.15560  0.3196  0.11510  \n",
       "8    0.53900  0.20600  0.4378  0.10720  \n",
       "9    1.10500  0.22100  0.4366  0.20750  \n",
       "10   0.14590  0.09975  0.2948  0.08452  \n",
       "11   0.39650  0.18100  0.3792  0.10480  \n",
       "12   0.36390  0.17670  0.3176  0.10230  \n",
       "13   0.23220  0.11190  0.2809  0.06287  \n",
       "14   0.69430  0.22080  0.3596  0.14310  \n",
       "15   0.70260  0.17120  0.4218  0.13410  \n",
       "16   0.29140  0.16090  0.3029  0.08216  \n",
       "17   0.47840  0.20730  0.3706  0.11420  \n",
       "18   0.53720  0.23880  0.2768  0.07615  \n",
       "19   0.23900  0.12880  0.2977  0.07259  \n",
       "20   0.18900  0.07283  0.3184  0.08183  \n",
       "21   0.08867  0.06227  0.2450  0.07773  \n",
       "22   0.63050  0.23930  0.4667  0.09946  \n",
       "23   0.31550  0.20090  0.2822  0.07526  \n",
       "24   0.46950  0.20950  0.3613  0.09564  \n",
       "25   0.38530  0.25500  0.4066  0.10590  \n",
       "26   0.55390  0.27010  0.4264  0.12750  \n",
       "27   0.34460  0.14900  0.2341  0.07421  \n",
       "28   0.63350  0.20240  0.4027  0.09876  \n",
       "29   0.24890  0.14560  0.2756  0.07919  \n",
       "..       ...      ...     ...      ...  \n",
       "539  0.33930  0.05000  0.2790  0.10660  \n",
       "540  0.17970  0.06918  0.2329  0.08134  \n",
       "541  0.40400  0.12050  0.3187  0.10230  \n",
       "542  0.16110  0.10950  0.2722  0.06956  \n",
       "543  0.10620  0.07958  0.2473  0.06443  \n",
       "544  0.13770  0.06845  0.2249  0.08492  \n",
       "545  0.10490  0.07174  0.2642  0.06953  \n",
       "546  0.04384  0.02381  0.2681  0.07399  \n",
       "547  0.17830  0.08333  0.2691  0.09479  \n",
       "548  0.09350  0.03846  0.2552  0.07920  \n",
       "549  0.06194  0.03264  0.3059  0.07626  \n",
       "550  0.00000  0.00000  0.2458  0.06592  \n",
       "551  0.15640  0.06413  0.3169  0.08032  \n",
       "552  0.08653  0.06498  0.2407  0.06484  \n",
       "553  0.07993  0.02564  0.2435  0.07393  \n",
       "554  0.24390  0.06493  0.2372  0.07242  \n",
       "555  0.20000  0.09127  0.2226  0.08283  \n",
       "556  0.01005  0.02232  0.2262  0.06742  \n",
       "557  0.00000  0.00000  0.2475  0.06969  \n",
       "558  0.36620  0.11050  0.2258  0.08004  \n",
       "559  0.36300  0.09653  0.2112  0.08732  \n",
       "560  0.13260  0.10480  0.2250  0.08321  \n",
       "561  0.00000  0.00000  0.1566  0.05905  \n",
       "562  1.17000  0.23560  0.4089  0.14090  \n",
       "563  0.65990  0.25420  0.2929  0.09873  \n",
       "564  0.41070  0.22160  0.2060  0.07115  \n",
       "565  0.32150  0.16280  0.2572  0.06637  \n",
       "566  0.34030  0.14180  0.2218  0.07820  \n",
       "567  0.93870  0.26500  0.4087  0.12400  \n",
       "568  0.00000  0.00000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
